{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22879,"status":"ok","timestamp":1684936239674,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"IwxWOpZQftXZ","outputId":"bc1883c5-4dfb-4c46-d177-cb3ea58165b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1289,"status":"ok","timestamp":1684936240959,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"5m5Td18_fz6b","outputId":"549b4e6e-52b6-4810-9dd6-3d4ad6e164b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg\n"]}],"source":["%cd /content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13126,"status":"ok","timestamp":1684936254072,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"ObmS_pk7f2E2","outputId":"467151c1-e96f-4988-8769-42e2e63806d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! pip install --quiet \"wandb\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8086,"status":"ok","timestamp":1684936262152,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"tlh1WU3DiznI","outputId":"0f2124ee-6508-4acb-a476-fd9907af5fff"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login # --relogin\n","# b3518f13f1b3184b76d233e2f2b1f7cbef587a1f"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176940,"status":"ok","timestamp":1684921710109,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"7TX_e8p4ftXc","outputId":"58851c8d-08cb-4f2d-ade6-ba3dd901dd6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:05<00:00,  3.90it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094604-5f29k613\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdenim-feather-57\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/5f29k613\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            bce\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100: 100% 15/15 [00:11<00:00,  1.31img/s, loss (batch)=0.704]\n","Epoch 2/100: 100% 15/15 [00:00<00:00, 25.02img/s, loss (batch)=0.694]\n","Epoch 3/100: 100% 15/15 [00:00<00:00, 20.95img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.7105249166488647\n","Epoch 4/100: 100% 15/15 [00:00<00:00, 23.95img/s, loss (batch)=0.693]\n","Epoch 5/100: 100% 15/15 [00:00<00:00, 31.63img/s, loss (batch)=0.693]\n","Epoch 6/100: 100% 15/15 [00:00<00:00, 31.09img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.698749303817749\n","Epoch 7/100: 100% 15/15 [00:00<00:00, 28.16img/s, loss (batch)=0.693]\n","Epoch 8/100: 100% 15/15 [00:00<00:00, 30.33img/s, loss (batch)=0.693]\n","Epoch 9/100: 100% 15/15 [00:00<00:00, 31.71img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931583881378174\n","Epoch 10/100: 100% 15/15 [00:00<00:00, 23.25img/s, loss (batch)=0.693]\n","Epoch 11/100: 100% 15/15 [00:00<00:00, 24.72img/s, loss (batch)=0.693]\n","Epoch 12/100: 100% 15/15 [00:00<00:00, 26.74img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931583285331726\n","Epoch 13/100: 100% 15/15 [00:00<00:00, 18.65img/s, loss (batch)=0.693]\n","Epoch 14/100: 100% 15/15 [00:00<00:00, 18.54img/s, loss (batch)=0.693]\n","Epoch 15/100: 100% 15/15 [00:00<00:00, 18.77img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931575536727905\n","Epoch 16/100: 100% 15/15 [00:00<00:00, 16.24img/s, loss (batch)=0.693]\n","Epoch 17/100: 100% 15/15 [00:00<00:00, 26.35img/s, loss (batch)=0.693]\n","Epoch 18/100: 100% 15/15 [00:00<00:00, 29.69img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6932926774024963\n","Epoch 19/100: 100% 15/15 [00:00<00:00, 28.42img/s, loss (batch)=0.693]\n","Epoch 20/100: 100% 15/15 [00:00<00:00, 31.92img/s, loss (batch)=0.693]\n","Epoch 21/100: 100% 15/15 [00:00<00:00, 30.63img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931567192077637\n","Epoch 22/100: 100% 15/15 [00:00<00:00, 28.38img/s, loss (batch)=0.692]\n","Epoch 23/100: 100% 15/15 [00:00<00:00, 29.56img/s, loss (batch)=0.693]\n","Epoch 24/100: 100% 15/15 [00:00<00:00, 28.61img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931619644165039\n","Epoch 25/100: 100% 15/15 [00:00<00:00, 27.99img/s, loss (batch)=0.692]\n","Epoch 26/100: 100% 15/15 [00:00<00:00, 28.59img/s, loss (batch)=0.691]\n","Epoch 27/100: 100% 15/15 [00:00<00:00, 31.65img/s, loss (batch)=0.691]\n","INFO: Validation loss score: 0.7068489193916321\n","Epoch 28/100: 100% 15/15 [00:00<00:00, 16.81img/s, loss (batch)=0.69]\n","Epoch 29/100: 100% 15/15 [00:00<00:00, 17.33img/s, loss (batch)=0.691]\n","Epoch 30/100: 100% 15/15 [00:00<00:00, 18.11img/s, loss (batch)=0.691]\n","INFO: Validation loss score: 0.7032908201217651\n","Epoch 31/100: 100% 15/15 [00:00<00:00, 18.37img/s, loss (batch)=0.691]\n","Epoch 32/100: 100% 15/15 [00:00<00:00, 28.14img/s, loss (batch)=0.69]\n","Epoch 33/100: 100% 15/15 [00:00<00:00, 29.03img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6906130313873291\n","Epoch 34/100: 100% 15/15 [00:00<00:00, 27.22img/s, loss (batch)=0.69]\n","Epoch 35/100: 100% 15/15 [00:00<00:00, 29.75img/s, loss (batch)=0.69]\n","Epoch 36/100: 100% 15/15 [00:00<00:00, 30.11img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6898869276046753\n","Epoch 37/100: 100% 15/15 [00:00<00:00, 30.13img/s, loss (batch)=0.691]\n","Epoch 38/100: 100% 15/15 [00:00<00:00, 31.32img/s, loss (batch)=0.69]\n","Epoch 39/100: 100% 15/15 [00:00<00:00, 29.74img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6942058801651001\n","Epoch 40/100: 100% 15/15 [00:00<00:00, 27.49img/s, loss (batch)=0.69]\n","Epoch 41/100: 100% 15/15 [00:00<00:00, 30.61img/s, loss (batch)=0.69]\n","Epoch 42/100: 100% 15/15 [00:00<00:00, 17.92img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.692255973815918\n","Epoch 43/100: 100% 15/15 [00:00<00:00, 15.31img/s, loss (batch)=0.689]\n","Epoch 44/100: 100% 15/15 [00:00<00:00, 17.25img/s, loss (batch)=0.69]\n","Epoch 45/100: 100% 15/15 [00:00<00:00, 18.86img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6918996572494507\n","Epoch 46/100: 100% 15/15 [00:00<00:00, 27.24img/s, loss (batch)=0.69]\n","Epoch 47/100: 100% 15/15 [00:00<00:00, 31.05img/s, loss (batch)=0.69]\n","Epoch 48/100: 100% 15/15 [00:00<00:00, 28.69img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6951764822006226\n","Epoch 49/100: 100% 15/15 [00:00<00:00, 27.48img/s, loss (batch)=0.69]\n","Epoch 50/100: 100% 15/15 [00:00<00:00, 30.96img/s, loss (batch)=0.69]\n","Epoch 51/100: 100% 15/15 [00:00<00:00, 30.49img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6919029951095581\n","INFO: New best model and checkpoint 51 saved!\n","Epoch 52/100: 100% 15/15 [00:00<00:00, 30.97img/s, loss (batch)=0.69]\n","Epoch 53/100: 100% 15/15 [00:00<00:00, 29.96img/s, loss (batch)=0.688]\n","Epoch 54/100: 100% 15/15 [00:00<00:00, 28.95img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6924113631248474\n","INFO: New best model and checkpoint 54 saved!\n","Epoch 55/100: 100% 15/15 [00:00<00:00, 16.86img/s, loss (batch)=0.686]\n","Epoch 56/100: 100% 15/15 [00:00<00:00, 23.27img/s, loss (batch)=0.688]\n","Epoch 57/100: 100% 15/15 [00:00<00:00, 31.21img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6881436109542847\n","Epoch 58/100: 100% 15/15 [00:00<00:00, 27.06img/s, loss (batch)=0.689]\n","Epoch 59/100: 100% 15/15 [00:00<00:00, 28.13img/s, loss (batch)=0.688]\n","Epoch 60/100: 100% 15/15 [00:00<00:00, 30.23img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6880858540534973\n","Epoch 61/100: 100% 15/15 [00:00<00:00, 26.64img/s, loss (batch)=0.689]\n","Epoch 62/100: 100% 15/15 [00:00<00:00, 26.60img/s, loss (batch)=0.688]\n","Epoch 63/100: 100% 15/15 [00:00<00:00, 29.39img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6880635023117065\n","Epoch 64/100: 100% 15/15 [00:00<00:00, 28.80img/s, loss (batch)=0.69]\n","Epoch 65/100: 100% 15/15 [00:00<00:00, 31.45img/s, loss (batch)=0.688]\n","Epoch 66/100: 100% 15/15 [00:00<00:00, 30.49img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.6881550550460815\n","Epoch 67/100: 100% 15/15 [00:00<00:00, 16.14img/s, loss (batch)=0.688]\n","Epoch 68/100: 100% 15/15 [00:00<00:00, 19.32img/s, loss (batch)=0.687]\n","Epoch 69/100: 100% 15/15 [00:00<00:00, 18.13img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6879830360412598\n","Epoch 70/100: 100% 15/15 [00:00<00:00, 19.68img/s, loss (batch)=0.687]\n","Epoch 71/100: 100% 15/15 [00:00<00:00, 28.72img/s, loss (batch)=0.688]\n","Epoch 72/100: 100% 15/15 [00:00<00:00, 29.95img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6879829168319702\n","Epoch 73/100: 100% 15/15 [00:00<00:00, 29.34img/s, loss (batch)=0.69]\n","Epoch 74/100: 100% 15/15 [00:00<00:00, 31.49img/s, loss (batch)=0.688]\n","Epoch 75/100: 100% 15/15 [00:00<00:00, 31.97img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6879499554634094\n","Epoch 76/100: 100% 15/15 [00:00<00:00, 29.39img/s, loss (batch)=0.688]\n","Epoch 77/100: 100% 15/15 [00:00<00:00, 27.62img/s, loss (batch)=0.688]\n","Epoch 78/100: 100% 15/15 [00:00<00:00, 28.46img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878793239593506\n","Epoch 79/100: 100% 15/15 [00:00<00:00, 27.71img/s, loss (batch)=0.69]\n","Epoch 80/100: 100% 15/15 [00:00<00:00, 31.57img/s, loss (batch)=0.688]\n","Epoch 81/100: 100% 15/15 [00:00<00:00, 25.92img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878786683082581\n","Epoch 82/100: 100% 15/15 [00:01<00:00, 14.36img/s, loss (batch)=0.69]\n","Epoch 83/100: 100% 15/15 [00:00<00:00, 18.35img/s, loss (batch)=0.689]\n","Epoch 84/100: 100% 15/15 [00:00<00:00, 18.22img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.687926173210144\n","Epoch 85/100: 100% 15/15 [00:00<00:00, 27.72img/s, loss (batch)=0.688]\n","Epoch 86/100: 100% 15/15 [00:00<00:00, 28.63img/s, loss (batch)=0.689]\n","Epoch 87/100: 100% 15/15 [00:00<00:00, 31.41img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6879758834838867\n","Epoch 88/100: 100% 15/15 [00:00<00:00, 29.57img/s, loss (batch)=0.689]\n","Epoch 89/100: 100% 15/15 [00:00<00:00, 28.83img/s, loss (batch)=0.688]\n","Epoch 90/100: 100% 15/15 [00:00<00:00, 31.84img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.6878597736358643\n","Epoch 91/100: 100% 15/15 [00:00<00:00, 27.68img/s, loss (batch)=0.69]\n","Epoch 92/100: 100% 15/15 [00:00<00:00, 29.74img/s, loss (batch)=0.689]\n","Epoch 93/100: 100% 15/15 [00:00<00:00, 32.69img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.688132643699646\n","Epoch 94/100: 100% 15/15 [00:00<00:00, 28.91img/s, loss (batch)=0.688]\n","Epoch 95/100: 100% 15/15 [00:00<00:00, 30.78img/s, loss (batch)=0.689]\n","Epoch 96/100: 100% 15/15 [00:00<00:00, 20.37img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6878831386566162\n","Epoch 97/100: 100% 15/15 [00:00<00:00, 15.96img/s, loss (batch)=0.688]\n","Epoch 98/100: 100% 15/15 [00:00<00:00, 20.60img/s, loss (batch)=0.686]\n","Epoch 99/100: 100% 15/15 [00:00<00:00, 20.72img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878526210784912\n","Epoch 100/100: 100% 15/15 [00:00<00:00, 27.71img/s, loss (batch)=0.687]\n","INFO: Last model and checkpoint 100 saved!\n","INFO: Train loss: 0.6882 | Train dice score: 0.4713 | Train iou: 0.3115 | Train f1: 0.4743\n","INFO: Val loss: 0.6878 | Val dice score: 0.4960 | Val iou: 0.3297 | Val f1: 0.4959\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in <module>\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 324, in train_model\n","    record = np.loadtxt('record.csv', delimiter=',')\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1163, in loadtxt\n","    chunk.append(packer(convert_row(words)))\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1142, in convert_row\n","    return [*map(_conv, vals)]\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 725, in _floatconv\n","    return float(x)  # The fastest path.\n","ValueError: could not convert string to float: 'train_loss'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–†â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step 400\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score 0.47129\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 0.47433\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou 0.31151\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss 0.68819\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score 0.49602\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 0.49585\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou 0.32966\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss 0.68785\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss 0.68785\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mdenim-feather-57\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/5f29k613\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 99 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094604-5f29k613/logs\u001b[0m\n"]}],"source":["!python train.py --loss bce -e 100"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132927,"status":"ok","timestamp":1684936647829,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"0oKob-KjOZ29","outputId":"9b22c120-8651-4c25-fed9-835140e2ee8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00<00:00, 114.87it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_135522-sif76t9o\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-shape-98\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/sif76t9o\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            energy\n","        Batch size:      1\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: False\n","    \n","Epoch 1/100: 100% 15/15 [00:02<00:00,  6.01img/s, loss (batch)=77.8]\n","Epoch 2/100: 100% 15/15 [00:01<00:00, 12.74img/s, loss (batch)=285]\n","Epoch 3/100: 100% 15/15 [00:01<00:00, 13.22img/s, loss (batch)=184]\n","INFO: Validation loss score: 163.59051513671875\n","Epoch 4/100: 100% 15/15 [00:01<00:00, 13.46img/s, loss (batch)=248]\n","Epoch 5/100: 100% 15/15 [00:00<00:00, 18.05img/s, loss (batch)=285]\n","Epoch 6/100: 100% 15/15 [00:00<00:00, 17.98img/s, loss (batch)=166]\n","INFO: Validation loss score: 163.83303833007812\n","Epoch 7/100: 100% 15/15 [00:00<00:00, 17.82img/s, loss (batch)=123]\n","Epoch 8/100: 100% 15/15 [00:00<00:00, 18.10img/s, loss (batch)=164]\n","Epoch 9/100: 100% 15/15 [00:00<00:00, 17.89img/s, loss (batch)=89.4]\n","INFO: Validation loss score: 163.2973175048828\n","Epoch 10/100: 100% 15/15 [00:00<00:00, 18.18img/s, loss (batch)=77.5]\n","Epoch 11/100: 100% 15/15 [00:00<00:00, 17.74img/s, loss (batch)=164]\n","Epoch 12/100: 100% 15/15 [00:00<00:00, 18.20img/s, loss (batch)=164]\n","INFO: Validation loss score: 163.7596435546875\n","Epoch 13/100: 100% 15/15 [00:00<00:00, 18.24img/s, loss (batch)=142]\n","Epoch 14/100: 100% 15/15 [00:00<00:00, 17.89img/s, loss (batch)=124]\n","Epoch 15/100: 100% 15/15 [00:00<00:00, 16.30img/s, loss (batch)=89.6]\n","INFO: Validation loss score: 163.49652099609375\n","Epoch 16/100: 100% 15/15 [00:01<00:00, 12.07img/s, loss (batch)=202]\n","Epoch 17/100: 100% 15/15 [00:01<00:00, 12.99img/s, loss (batch)=176]\n","Epoch 18/100: 100% 15/15 [00:01<00:00, 13.50img/s, loss (batch)=144]\n","INFO: Validation loss score: 163.32516479492188\n","Epoch 19/100: 100% 15/15 [00:00<00:00, 16.27img/s, loss (batch)=167]\n","Epoch 20/100: 100% 15/15 [00:00<00:00, 17.94img/s, loss (batch)=153]\n","Epoch 21/100: 100% 15/15 [00:00<00:00, 17.65img/s, loss (batch)=155]\n","INFO: Validation loss score: 163.28538513183594\n","Epoch 22/100: 100% 15/15 [00:00<00:00, 17.23img/s, loss (batch)=167]\n","Epoch 23/100: 100% 15/15 [00:00<00:00, 17.49img/s, loss (batch)=154]\n","Epoch 24/100: 100% 15/15 [00:00<00:00, 18.34img/s, loss (batch)=146]\n","INFO: Validation loss score: 165.14111328125\n","Epoch 25/100: 100% 15/15 [00:00<00:00, 17.81img/s, loss (batch)=250]\n","Epoch 26/100: 100% 15/15 [00:00<00:00, 17.05img/s, loss (batch)=168]\n","Epoch 27/100: 100% 15/15 [00:00<00:00, 17.64img/s, loss (batch)=127]\n","INFO: Validation loss score: 163.2884521484375\n","Epoch 28/100: 100% 15/15 [00:00<00:00, 17.72img/s, loss (batch)=187]\n","Epoch 29/100: 100% 15/15 [00:00<00:00, 16.90img/s, loss (batch)=180]\n","Epoch 30/100: 100% 15/15 [00:01<00:00, 13.04img/s, loss (batch)=119]\n","INFO: Validation loss score: 165.70396423339844\n","Epoch 31/100: 100% 15/15 [00:01<00:00, 12.07img/s, loss (batch)=171]\n","Epoch 32/100: 100% 15/15 [00:01<00:00, 13.42img/s, loss (batch)=182]\n","Epoch 33/100: 100% 15/15 [00:01<00:00, 13.81img/s, loss (batch)=293]\n","INFO: Validation loss score: 168.8467559814453\n","Epoch 34/100: 100% 15/15 [00:00<00:00, 17.93img/s, loss (batch)=80.4]\n","Epoch 35/100: 100% 15/15 [00:00<00:00, 17.26img/s, loss (batch)=127]\n","Epoch 36/100: 100% 15/15 [00:00<00:00, 18.23img/s, loss (batch)=293]\n","INFO: Validation loss score: 169.2168426513672\n","Epoch 37/100: 100% 15/15 [00:00<00:00, 17.20img/s, loss (batch)=171]\n","Epoch 38/100: 100% 15/15 [00:00<00:00, 18.11img/s, loss (batch)=170]\n","Epoch 39/100: 100% 15/15 [00:00<00:00, 17.28img/s, loss (batch)=294]\n","INFO: Validation loss score: 169.20526123046875\n","Epoch 40/100: 100% 15/15 [00:00<00:00, 16.98img/s, loss (batch)=148]\n","Epoch 41/100: 100% 15/15 [00:00<00:00, 17.54img/s, loss (batch)=93.2]\n","Epoch 42/100: 100% 15/15 [00:00<00:00, 17.96img/s, loss (batch)=171]\n","INFO: Validation loss score: 168.7367401123047\n","Epoch 43/100: 100% 15/15 [00:00<00:00, 16.72img/s, loss (batch)=172]\n","Epoch 44/100: 100% 15/15 [00:01<00:00, 12.46img/s, loss (batch)=205]\n","Epoch 45/100: 100% 15/15 [00:01<00:00, 12.01img/s, loss (batch)=182]\n","INFO: Validation loss score: 165.3176727294922\n","Epoch 46/100: 100% 15/15 [00:01<00:00, 12.28img/s, loss (batch)=253]\n","Epoch 47/100: 100% 15/15 [00:01<00:00, 12.69img/s, loss (batch)=81.1]\n","Epoch 48/100: 100% 15/15 [00:00<00:00, 17.72img/s, loss (batch)=189]\n","INFO: Validation loss score: 170.32835388183594\n","Epoch 49/100: 100% 15/15 [00:00<00:00, 17.58img/s, loss (batch)=253]\n","Epoch 50/100: 100% 15/15 [00:00<00:00, 16.86img/s, loss (batch)=157]\n","Epoch 51/100: 100% 15/15 [00:00<00:00, 17.62img/s, loss (batch)=189]\n","INFO: Validation loss score: 169.77685546875\n","INFO: New best model and checkpoint 51 saved!\n","Epoch 52/100: 100% 15/15 [00:00<00:00, 17.42img/s, loss (batch)=120]\n","Epoch 53/100: 100% 15/15 [00:00<00:00, 17.41img/s, loss (batch)=205]\n","Epoch 54/100: 100% 15/15 [00:00<00:00, 17.49img/s, loss (batch)=189]\n","INFO: Validation loss score: 169.63772583007812\n","Epoch 55/100: 100% 15/15 [00:00<00:00, 17.89img/s, loss (batch)=295]\n","Epoch 56/100: 100% 15/15 [00:00<00:00, 17.60img/s, loss (batch)=128]\n","Epoch 57/100: 100% 15/15 [00:00<00:00, 17.59img/s, loss (batch)=253]\n","INFO: Validation loss score: 169.9619903564453\n","INFO: New best model and checkpoint 57 saved!\n","Epoch 58/100: 100% 15/15 [00:01<00:00, 12.13img/s, loss (batch)=81.3]\n","Epoch 59/100: 100% 15/15 [00:01<00:00, 11.80img/s, loss (batch)=189]\n","Epoch 60/100: 100% 15/15 [00:01<00:00, 12.08img/s, loss (batch)=93.7]\n","INFO: Validation loss score: 169.71705627441406\n","Epoch 61/100: 100% 15/15 [00:01<00:00, 14.34img/s, loss (batch)=157]\n","Epoch 62/100: 100% 15/15 [00:00<00:00, 17.63img/s, loss (batch)=172]\n","Epoch 63/100: 100% 15/15 [00:00<00:00, 16.51img/s, loss (batch)=128]\n","INFO: Validation loss score: 169.7143096923828\n","Epoch 64/100: 100% 15/15 [00:00<00:00, 18.09img/s, loss (batch)=149]\n","Epoch 65/100: 100% 15/15 [00:00<00:00, 16.99img/s, loss (batch)=128]\n","Epoch 66/100: 100% 15/15 [00:00<00:00, 18.08img/s, loss (batch)=172]\n","INFO: Validation loss score: 169.96376037597656\n","INFO: New best model and checkpoint 66 saved!\n","Epoch 67/100: 100% 15/15 [00:00<00:00, 17.59img/s, loss (batch)=172]\n","Epoch 68/100: 100% 15/15 [00:00<00:00, 17.79img/s, loss (batch)=295]\n","Epoch 69/100: 100% 15/15 [00:00<00:00, 18.27img/s, loss (batch)=129]\n","INFO: Validation loss score: 169.92552185058594\n","Epoch 70/100: 100% 15/15 [00:00<00:00, 18.06img/s, loss (batch)=172]\n","Epoch 71/100: 100% 15/15 [00:00<00:00, 16.19img/s, loss (batch)=171]\n","Epoch 72/100: 100% 15/15 [00:01<00:00, 12.98img/s, loss (batch)=149]\n","INFO: Validation loss score: 169.9920654296875\n","INFO: New best model and checkpoint 72 saved!\n","Epoch 73/100: 100% 15/15 [00:00<00:00, 15.26img/s, loss (batch)=157]\n","Epoch 74/100: 100% 15/15 [00:00<00:00, 17.13img/s, loss (batch)=182]\n","Epoch 75/100: 100% 15/15 [00:00<00:00, 17.39img/s, loss (batch)=93.7]\n","INFO: Validation loss score: 169.84786987304688\n","Epoch 76/100: 100% 15/15 [00:00<00:00, 17.64img/s, loss (batch)=205]\n","Epoch 77/100: 100% 15/15 [00:00<00:00, 17.51img/s, loss (batch)=172]\n","Epoch 78/100: 100% 15/15 [00:00<00:00, 18.00img/s, loss (batch)=182]\n","INFO: Validation loss score: 170.03192138671875\n","INFO: New best model and checkpoint 78 saved!\n","Epoch 79/100: 100% 15/15 [00:00<00:00, 16.02img/s, loss (batch)=171]\n","Epoch 80/100: 100% 15/15 [00:00<00:00, 18.44img/s, loss (batch)=173]\n","Epoch 81/100: 100% 15/15 [00:00<00:00, 17.45img/s, loss (batch)=157]\n","INFO: Validation loss score: 170.0376739501953\n","INFO: New best model and checkpoint 81 saved!\n","Epoch 82/100: 100% 15/15 [00:01<00:00, 11.89img/s, loss (batch)=253]\n","Epoch 83/100: 100% 15/15 [00:01<00:00, 10.13img/s, loss (batch)=81.4]\n","Epoch 84/100: 100% 15/15 [00:01<00:00, 13.18img/s, loss (batch)=205]\n","INFO: Validation loss score: 170.03916931152344\n","INFO: New best model and checkpoint 84 saved!\n","Epoch 85/100: 100% 15/15 [00:00<00:00, 17.61img/s, loss (batch)=182]\n","Epoch 86/100: 100% 15/15 [00:00<00:00, 17.62img/s, loss (batch)=149]\n","Epoch 87/100: 100% 15/15 [00:00<00:00, 17.86img/s, loss (batch)=189]\n","INFO: Validation loss score: 170.0671844482422\n","INFO: New best model and checkpoint 87 saved!\n","Epoch 88/100: 100% 15/15 [00:00<00:00, 16.21img/s, loss (batch)=157]\n","Epoch 89/100: 100% 15/15 [00:00<00:00, 17.69img/s, loss (batch)=205]\n","Epoch 90/100: 100% 15/15 [00:00<00:00, 17.97img/s, loss (batch)=205]\n","INFO: Validation loss score: 170.07723999023438\n","INFO: New best model and checkpoint 90 saved!\n","Epoch 91/100: 100% 15/15 [00:00<00:00, 15.82img/s, loss (batch)=93.7]\n","Epoch 92/100: 100% 15/15 [00:00<00:00, 17.08img/s, loss (batch)=157]\n","Epoch 93/100: 100% 15/15 [00:00<00:00, 17.98img/s, loss (batch)=189]\n","INFO: Validation loss score: 169.9717254638672\n","Epoch 94/100: 100% 15/15 [00:00<00:00, 16.49img/s, loss (batch)=189]\n","Epoch 95/100: 100% 15/15 [00:01<00:00, 11.48img/s, loss (batch)=172]\n","Epoch 96/100: 100% 15/15 [00:01<00:00, 13.00img/s, loss (batch)=295]\n","INFO: Validation loss score: 170.01890563964844\n","Epoch 97/100: 100% 15/15 [00:01<00:00, 13.46img/s, loss (batch)=182]\n","Epoch 98/100: 100% 15/15 [00:01<00:00, 12.56img/s, loss (batch)=205]\n","Epoch 99/100: 100% 15/15 [00:00<00:00, 18.04img/s, loss (batch)=173]\n","INFO: Validation loss score: 170.03392028808594\n","Epoch 100/100: 100% 15/15 [00:00<00:00, 16.90img/s, loss (batch)=173]\n","INFO: Last model and checkpoint 100 saved!\n","INFO: Train loss: 168.3906 | Train dice score: 0.1187 | Train iou: 0.0632 | Train f1: 0.1187\n","INFO: Val loss: 170.0014 | Val dice score: 0.1185 | Val iou: 0.0631 | Val f1: 0.1185\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 405, in <module>\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 332, in train_model\n","    pd.Series([\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 461, in __init__\n","    com.require_length_match(data, index)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\", line 571, in require_length_match\n","    raise ValueError(\n","ValueError: Length of values (8) does not match length of index (9)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss â–â–„â–†â–„â–ƒâ–â–…â–‚â–â–„â–„â–ˆâ–‚â–‡â–…â–„â–â–„â–‚â–…â–ƒâ–„â–„â–ƒâ–â–ƒâ–‡â–‡â–„â–â–„â–‡â–„â–â–â–ˆâ–…â–ƒâ–ˆâ–\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss â–â–‚â–â–â–â–â–â–ƒâ–â–ƒâ–‡â–‡â–‡â–†â–ƒâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step 1500\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score 0.1187\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 0.1187\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou 0.06321\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss 168.39064\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score 0.11848\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 0.11848\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou 0.06307\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss 170.00145\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss 170.03392\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mdry-shape-98\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/sif76t9o\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 99 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_135522-sif76t9o/logs\u001b[0m\n"]}],"source":["!python train.py --loss energy -b 1 -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19461,"status":"ok","timestamp":1684921747572,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"f77s-2B-OdIO","outputId":"e9c919a2-4521-4b3a-8fc3-fbff2f17262d"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00<00:00, 59.05it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094856-4cr8we8s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtreasured-elevator-59\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/4cr8we8s\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            ac\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100:   0% 0/15 [00:02<?, ?img/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in <module>\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 224, in train_model\n","    loss = criterion(masks_pred.squeeze(1), true_masks.float())\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/utils/active_contour_loss.py\", line 49, in forward\n","    grd_x = self.diff_x(predication)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","RuntimeError: Input type (torch.cuda.HalfTensor) and weight type (torch.FloatTensor) should be the same\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mtreasured-elevator-59\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/4cr8we8s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094856-4cr8we8s/logs\u001b[0m\n"]}],"source":["!python train.py --loss ac -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31439,"status":"ok","timestamp":1684921778976,"user":{"displayName":"è’‹æ–‡é¦¨","userId":"06690486615691037725"},"user_tz":-480},"id":"Tqebm15iOhyl","outputId":"2464ce10-c5aa-4758-e565-f9d72004a503"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00<00:00, 114.02it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094916-7qvdu23y\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlight-mountain-60\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/7qvdu23y\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            nll\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100: 100% 15/15 [00:02<00:00,  5.81img/s, loss (batch)=5.55]\n","Epoch 2/100: 100% 15/15 [00:00<00:00, 32.64img/s, loss (batch)=5.55]\n","Epoch 3/100: 100% 15/15 [00:00<00:00, 34.42img/s, loss (batch)=5.55]\n","INFO: Validation loss score: 5.548685073852539\n","Epoch 4/100: 100% 15/15 [00:00<00:00, 27.28img/s, loss (batch)=5.54]\n","Epoch 5/100: 100% 15/15 [00:00<00:00, 18.57img/s, loss (batch)=5.54]\n","Epoch 6/100: 100% 15/15 [00:00<00:00, 19.04img/s, loss (batch)=5.53]\n","INFO: Validation loss score: 5.545119285583496\n","Epoch 7/100: 100% 15/15 [00:00<00:00, 16.89img/s, loss (batch)=5.51]\n","Epoch 8/100: 100% 15/15 [00:00<00:00, 17.49img/s, loss (batch)=5.48]\n","Epoch 9/100: 100% 15/15 [00:00<00:00, 28.32img/s, loss (batch)=5.43]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in <module>\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 250, in train_model\n","    histograms['Gradients/' + tag] = wandb.Histogram(\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/data_types/histogram.py\", line 76, in __init__\n","    self.histogram, self.bins = np.histogram(sequence, bins=num_bins)\n","  File \"<__array_function__ internals>\", line 180, in histogram\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 793, in histogram\n","    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 426, in _get_bin_edges\n","    first_edge, last_edge = _get_outer_edges(a, range)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 323, in _get_outer_edges\n","    raise ValueError(\n","ValueError: autodetected range of [nan, nan] is not finite\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           epoch â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:   learning rate â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:            step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: validation loss â–ˆâ–\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 9\n","\u001b[34m\u001b[1mwandb\u001b[0m:   learning rate 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m:            step 36\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train loss 5.43493\n","\u001b[34m\u001b[1mwandb\u001b[0m: validation loss 5.54512\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mlight-mountain-60\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/7qvdu23y\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 6 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094916-7qvdu23y/logs\u001b[0m\n"]}],"source":["!python train.py --loss nll -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ca4IvYKTOlw3","outputId":"8dfbefe0-3329-4f73-b927-220076636804"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00<00:00, 115.12it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094947-hoyraxyd\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-pond-61\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/hoyraxyd\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            dice\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100:   0% 0/15 [00:01<?, ?img/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in <module>\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 221, in train_model\n","    masks_pred = model(images)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/unet.py\", line 46, in forward\n","    enc1 = self.encoder1(x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","KeyboardInterrupt\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mrural-pond-61\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/hoyraxyd\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094947-hoyraxyd/logs\u001b[0m\n","^C\n"]}],"source":["!python train.py --loss dice -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lExA-sH_OnRu"},"outputs":[],"source":["!python train.py --loss dice_bce -e 100"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}