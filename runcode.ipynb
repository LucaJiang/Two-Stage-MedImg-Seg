{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26166,"status":"ok","timestamp":1684921506699,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"IwxWOpZQftXZ","outputId":"a298f750-a914-49a6-887b-cb0a7c385c62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1104,"status":"ok","timestamp":1684921512620,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"5m5Td18_fz6b","outputId":"211e6788-ba6e-4a2e-965b-3611160f24a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg\n"]}],"source":["%cd /content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11696,"status":"ok","timestamp":1684921524874,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"ObmS_pk7f2E2","outputId":"5d38c886-9808-4618-d0fe-49679afd6889"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! pip install --quiet \"wandb\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8312,"status":"ok","timestamp":1684921533176,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"tlh1WU3DiznI","outputId":"76fa7779-b3be-441d-e29a-41d952348d9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W\u0026B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login # --relogin\n","# b3518f13f1b3184b76d233e2f2b1f7cbef587a1f"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176940,"status":"ok","timestamp":1684921710109,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"7TX_e8p4ftXc","outputId":"58851c8d-08cb-4f2d-ade6-ba3dd901dd6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:05\u003c00:00,  3.90it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094604-5f29k613\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdenim-feather-57\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/5f29k613\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            bce\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100: 100% 15/15 [00:11\u003c00:00,  1.31img/s, loss (batch)=0.704]\n","Epoch 2/100: 100% 15/15 [00:00\u003c00:00, 25.02img/s, loss (batch)=0.694]\n","Epoch 3/100: 100% 15/15 [00:00\u003c00:00, 20.95img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.7105249166488647\n","Epoch 4/100: 100% 15/15 [00:00\u003c00:00, 23.95img/s, loss (batch)=0.693]\n","Epoch 5/100: 100% 15/15 [00:00\u003c00:00, 31.63img/s, loss (batch)=0.693]\n","Epoch 6/100: 100% 15/15 [00:00\u003c00:00, 31.09img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.698749303817749\n","Epoch 7/100: 100% 15/15 [00:00\u003c00:00, 28.16img/s, loss (batch)=0.693]\n","Epoch 8/100: 100% 15/15 [00:00\u003c00:00, 30.33img/s, loss (batch)=0.693]\n","Epoch 9/100: 100% 15/15 [00:00\u003c00:00, 31.71img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931583881378174\n","Epoch 10/100: 100% 15/15 [00:00\u003c00:00, 23.25img/s, loss (batch)=0.693]\n","Epoch 11/100: 100% 15/15 [00:00\u003c00:00, 24.72img/s, loss (batch)=0.693]\n","Epoch 12/100: 100% 15/15 [00:00\u003c00:00, 26.74img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931583285331726\n","Epoch 13/100: 100% 15/15 [00:00\u003c00:00, 18.65img/s, loss (batch)=0.693]\n","Epoch 14/100: 100% 15/15 [00:00\u003c00:00, 18.54img/s, loss (batch)=0.693]\n","Epoch 15/100: 100% 15/15 [00:00\u003c00:00, 18.77img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931575536727905\n","Epoch 16/100: 100% 15/15 [00:00\u003c00:00, 16.24img/s, loss (batch)=0.693]\n","Epoch 17/100: 100% 15/15 [00:00\u003c00:00, 26.35img/s, loss (batch)=0.693]\n","Epoch 18/100: 100% 15/15 [00:00\u003c00:00, 29.69img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6932926774024963\n","Epoch 19/100: 100% 15/15 [00:00\u003c00:00, 28.42img/s, loss (batch)=0.693]\n","Epoch 20/100: 100% 15/15 [00:00\u003c00:00, 31.92img/s, loss (batch)=0.693]\n","Epoch 21/100: 100% 15/15 [00:00\u003c00:00, 30.63img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931567192077637\n","Epoch 22/100: 100% 15/15 [00:00\u003c00:00, 28.38img/s, loss (batch)=0.692]\n","Epoch 23/100: 100% 15/15 [00:00\u003c00:00, 29.56img/s, loss (batch)=0.693]\n","Epoch 24/100: 100% 15/15 [00:00\u003c00:00, 28.61img/s, loss (batch)=0.693]\n","INFO: Validation loss score: 0.6931619644165039\n","Epoch 25/100: 100% 15/15 [00:00\u003c00:00, 27.99img/s, loss (batch)=0.692]\n","Epoch 26/100: 100% 15/15 [00:00\u003c00:00, 28.59img/s, loss (batch)=0.691]\n","Epoch 27/100: 100% 15/15 [00:00\u003c00:00, 31.65img/s, loss (batch)=0.691]\n","INFO: Validation loss score: 0.7068489193916321\n","Epoch 28/100: 100% 15/15 [00:00\u003c00:00, 16.81img/s, loss (batch)=0.69]\n","Epoch 29/100: 100% 15/15 [00:00\u003c00:00, 17.33img/s, loss (batch)=0.691]\n","Epoch 30/100: 100% 15/15 [00:00\u003c00:00, 18.11img/s, loss (batch)=0.691]\n","INFO: Validation loss score: 0.7032908201217651\n","Epoch 31/100: 100% 15/15 [00:00\u003c00:00, 18.37img/s, loss (batch)=0.691]\n","Epoch 32/100: 100% 15/15 [00:00\u003c00:00, 28.14img/s, loss (batch)=0.69]\n","Epoch 33/100: 100% 15/15 [00:00\u003c00:00, 29.03img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6906130313873291\n","Epoch 34/100: 100% 15/15 [00:00\u003c00:00, 27.22img/s, loss (batch)=0.69]\n","Epoch 35/100: 100% 15/15 [00:00\u003c00:00, 29.75img/s, loss (batch)=0.69]\n","Epoch 36/100: 100% 15/15 [00:00\u003c00:00, 30.11img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6898869276046753\n","Epoch 37/100: 100% 15/15 [00:00\u003c00:00, 30.13img/s, loss (batch)=0.691]\n","Epoch 38/100: 100% 15/15 [00:00\u003c00:00, 31.32img/s, loss (batch)=0.69]\n","Epoch 39/100: 100% 15/15 [00:00\u003c00:00, 29.74img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6942058801651001\n","Epoch 40/100: 100% 15/15 [00:00\u003c00:00, 27.49img/s, loss (batch)=0.69]\n","Epoch 41/100: 100% 15/15 [00:00\u003c00:00, 30.61img/s, loss (batch)=0.69]\n","Epoch 42/100: 100% 15/15 [00:00\u003c00:00, 17.92img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.692255973815918\n","Epoch 43/100: 100% 15/15 [00:00\u003c00:00, 15.31img/s, loss (batch)=0.689]\n","Epoch 44/100: 100% 15/15 [00:00\u003c00:00, 17.25img/s, loss (batch)=0.69]\n","Epoch 45/100: 100% 15/15 [00:00\u003c00:00, 18.86img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6918996572494507\n","Epoch 46/100: 100% 15/15 [00:00\u003c00:00, 27.24img/s, loss (batch)=0.69]\n","Epoch 47/100: 100% 15/15 [00:00\u003c00:00, 31.05img/s, loss (batch)=0.69]\n","Epoch 48/100: 100% 15/15 [00:00\u003c00:00, 28.69img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6951764822006226\n","Epoch 49/100: 100% 15/15 [00:00\u003c00:00, 27.48img/s, loss (batch)=0.69]\n","Epoch 50/100: 100% 15/15 [00:00\u003c00:00, 30.96img/s, loss (batch)=0.69]\n","Epoch 51/100: 100% 15/15 [00:00\u003c00:00, 30.49img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6919029951095581\n","INFO: New best model and checkpoint 51 saved!\n","Epoch 52/100: 100% 15/15 [00:00\u003c00:00, 30.97img/s, loss (batch)=0.69]\n","Epoch 53/100: 100% 15/15 [00:00\u003c00:00, 29.96img/s, loss (batch)=0.688]\n","Epoch 54/100: 100% 15/15 [00:00\u003c00:00, 28.95img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6924113631248474\n","INFO: New best model and checkpoint 54 saved!\n","Epoch 55/100: 100% 15/15 [00:00\u003c00:00, 16.86img/s, loss (batch)=0.686]\n","Epoch 56/100: 100% 15/15 [00:00\u003c00:00, 23.27img/s, loss (batch)=0.688]\n","Epoch 57/100: 100% 15/15 [00:00\u003c00:00, 31.21img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6881436109542847\n","Epoch 58/100: 100% 15/15 [00:00\u003c00:00, 27.06img/s, loss (batch)=0.689]\n","Epoch 59/100: 100% 15/15 [00:00\u003c00:00, 28.13img/s, loss (batch)=0.688]\n","Epoch 60/100: 100% 15/15 [00:00\u003c00:00, 30.23img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6880858540534973\n","Epoch 61/100: 100% 15/15 [00:00\u003c00:00, 26.64img/s, loss (batch)=0.689]\n","Epoch 62/100: 100% 15/15 [00:00\u003c00:00, 26.60img/s, loss (batch)=0.688]\n","Epoch 63/100: 100% 15/15 [00:00\u003c00:00, 29.39img/s, loss (batch)=0.689]\n","INFO: Validation loss score: 0.6880635023117065\n","Epoch 64/100: 100% 15/15 [00:00\u003c00:00, 28.80img/s, loss (batch)=0.69]\n","Epoch 65/100: 100% 15/15 [00:00\u003c00:00, 31.45img/s, loss (batch)=0.688]\n","Epoch 66/100: 100% 15/15 [00:00\u003c00:00, 30.49img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.6881550550460815\n","Epoch 67/100: 100% 15/15 [00:00\u003c00:00, 16.14img/s, loss (batch)=0.688]\n","Epoch 68/100: 100% 15/15 [00:00\u003c00:00, 19.32img/s, loss (batch)=0.687]\n","Epoch 69/100: 100% 15/15 [00:00\u003c00:00, 18.13img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6879830360412598\n","Epoch 70/100: 100% 15/15 [00:00\u003c00:00, 19.68img/s, loss (batch)=0.687]\n","Epoch 71/100: 100% 15/15 [00:00\u003c00:00, 28.72img/s, loss (batch)=0.688]\n","Epoch 72/100: 100% 15/15 [00:00\u003c00:00, 29.95img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6879829168319702\n","Epoch 73/100: 100% 15/15 [00:00\u003c00:00, 29.34img/s, loss (batch)=0.69]\n","Epoch 74/100: 100% 15/15 [00:00\u003c00:00, 31.49img/s, loss (batch)=0.688]\n","Epoch 75/100: 100% 15/15 [00:00\u003c00:00, 31.97img/s, loss (batch)=0.69]\n","INFO: Validation loss score: 0.6879499554634094\n","Epoch 76/100: 100% 15/15 [00:00\u003c00:00, 29.39img/s, loss (batch)=0.688]\n","Epoch 77/100: 100% 15/15 [00:00\u003c00:00, 27.62img/s, loss (batch)=0.688]\n","Epoch 78/100: 100% 15/15 [00:00\u003c00:00, 28.46img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878793239593506\n","Epoch 79/100: 100% 15/15 [00:00\u003c00:00, 27.71img/s, loss (batch)=0.69]\n","Epoch 80/100: 100% 15/15 [00:00\u003c00:00, 31.57img/s, loss (batch)=0.688]\n","Epoch 81/100: 100% 15/15 [00:00\u003c00:00, 25.92img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878786683082581\n","Epoch 82/100: 100% 15/15 [00:01\u003c00:00, 14.36img/s, loss (batch)=0.69]\n","Epoch 83/100: 100% 15/15 [00:00\u003c00:00, 18.35img/s, loss (batch)=0.689]\n","Epoch 84/100: 100% 15/15 [00:00\u003c00:00, 18.22img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.687926173210144\n","Epoch 85/100: 100% 15/15 [00:00\u003c00:00, 27.72img/s, loss (batch)=0.688]\n","Epoch 86/100: 100% 15/15 [00:00\u003c00:00, 28.63img/s, loss (batch)=0.689]\n","Epoch 87/100: 100% 15/15 [00:00\u003c00:00, 31.41img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6879758834838867\n","Epoch 88/100: 100% 15/15 [00:00\u003c00:00, 29.57img/s, loss (batch)=0.689]\n","Epoch 89/100: 100% 15/15 [00:00\u003c00:00, 28.83img/s, loss (batch)=0.688]\n","Epoch 90/100: 100% 15/15 [00:00\u003c00:00, 31.84img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.6878597736358643\n","Epoch 91/100: 100% 15/15 [00:00\u003c00:00, 27.68img/s, loss (batch)=0.69]\n","Epoch 92/100: 100% 15/15 [00:00\u003c00:00, 29.74img/s, loss (batch)=0.689]\n","Epoch 93/100: 100% 15/15 [00:00\u003c00:00, 32.69img/s, loss (batch)=0.686]\n","INFO: Validation loss score: 0.688132643699646\n","Epoch 94/100: 100% 15/15 [00:00\u003c00:00, 28.91img/s, loss (batch)=0.688]\n","Epoch 95/100: 100% 15/15 [00:00\u003c00:00, 30.78img/s, loss (batch)=0.689]\n","Epoch 96/100: 100% 15/15 [00:00\u003c00:00, 20.37img/s, loss (batch)=0.687]\n","INFO: Validation loss score: 0.6878831386566162\n","Epoch 97/100: 100% 15/15 [00:00\u003c00:00, 15.96img/s, loss (batch)=0.688]\n","Epoch 98/100: 100% 15/15 [00:00\u003c00:00, 20.60img/s, loss (batch)=0.686]\n","Epoch 99/100: 100% 15/15 [00:00\u003c00:00, 20.72img/s, loss (batch)=0.688]\n","INFO: Validation loss score: 0.6878526210784912\n","Epoch 100/100: 100% 15/15 [00:00\u003c00:00, 27.71img/s, loss (batch)=0.687]\n","INFO: Last model and checkpoint 100 saved!\n","INFO: Train loss: 0.6882 | Train dice score: 0.4713 | Train iou: 0.3115 | Train f1: 0.4743\n","INFO: Val loss: 0.6878 | Val dice score: 0.4960 | Val iou: 0.3297 | Val f1: 0.4959\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in \u003cmodule\u003e\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 324, in train_model\n","    record = np.loadtxt('record.csv', delimiter=',')\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1163, in loadtxt\n","    chunk.append(packer(convert_row(words)))\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1142, in convert_row\n","    return [*map(_conv, vals)]\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 725, in _floatconv\n","    return float(x)  # The fastest path.\n","ValueError: could not convert string to float: 'train_loss'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate ████████▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss █▄▄▄▄▄▄▄▄▃▃▂▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss █▄▃▃▃▃▃▃▇▆▂▂▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    learning rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:             step 400\n","\u001b[34m\u001b[1mwandb\u001b[0m: train dice score 0.47129\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train f1 0.47433\n","\u001b[34m\u001b[1mwandb\u001b[0m:        train iou 0.31151\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train loss 0.68819\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val dice score 0.49602\n","\u001b[34m\u001b[1mwandb\u001b[0m:           val f1 0.49585\n","\u001b[34m\u001b[1mwandb\u001b[0m:          val iou 0.32966\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val loss 0.68785\n","\u001b[34m\u001b[1mwandb\u001b[0m:  validation loss 0.68785\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdenim-feather-57\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/5f29k613\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 99 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094604-5f29k613/logs\u001b[0m\n"]}],"source":["!python train.py --loss bce -e 100"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18016,"status":"ok","timestamp":1684921728118,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"0oKob-KjOZ29","outputId":"9c0f0a3a-c334-492e-9161-b8ce237a4a11"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00\u003c00:00, 109.62it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094837-xddqnrsv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-meadow-58\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/xddqnrsv\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            energy\n","        Batch size:      1\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100: 100% 15/15 [00:03\u003c00:00,  4.85img/s, loss (batch)=0.00474]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in \u003cmodule\u003e\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 250, in train_model\n","    histograms['Gradients/' + tag] = wandb.Histogram(\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/data_types/histogram.py\", line 76, in __init__\n","    self.histogram, self.bins = np.histogram(sequence, bins=num_bins)\n","  File \"\u003c__array_function__ internals\u003e\", line 180, in histogram\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 793, in histogram\n","    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 426, in _get_bin_edges\n","    first_edge, last_edge = _get_outer_edges(a, range)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 323, in _get_outer_edges\n","    raise ValueError(\n","ValueError: autodetected range of [nan, nan] is not finite\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       step ▁▁▂▃▃▃▄▅▅▅▆▇▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m: train loss ▄▄▄▃▄▃▃▅▄▁▃█▁▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1\n","\u001b[34m\u001b[1mwandb\u001b[0m:       step 15\n","\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.00474\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdaily-meadow-58\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/xddqnrsv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094837-xddqnrsv/logs\u001b[0m\n"]}],"source":["!python train.py --loss energy -b 1 -e 100"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19461,"status":"ok","timestamp":1684921747572,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"f77s-2B-OdIO","outputId":"e9c919a2-4521-4b3a-8fc3-fbff2f17262d"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00\u003c00:00, 59.05it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094856-4cr8we8s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtreasured-elevator-59\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/4cr8we8s\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            ac\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100:   0% 0/15 [00:02\u003c?, ?img/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in \u003cmodule\u003e\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 224, in train_model\n","    loss = criterion(masks_pred.squeeze(1), true_masks.float())\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/utils/active_contour_loss.py\", line 49, in forward\n","    grd_x = self.diff_x(predication)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","RuntimeError: Input type (torch.cuda.HalfTensor) and weight type (torch.FloatTensor) should be the same\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtreasured-elevator-59\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/4cr8we8s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094856-4cr8we8s/logs\u001b[0m\n"]}],"source":["!python train.py --loss ac -e 100"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31439,"status":"ok","timestamp":1684921778976,"user":{"displayName":"蒋文馨","userId":"06690486615691037725"},"user_tz":-480},"id":"Tqebm15iOhyl","outputId":"2464ce10-c5aa-4758-e565-f9d72004a503"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00\u003c00:00, 114.02it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094916-7qvdu23y\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlight-mountain-60\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/7qvdu23y\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            nll\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100: 100% 15/15 [00:02\u003c00:00,  5.81img/s, loss (batch)=5.55]\n","Epoch 2/100: 100% 15/15 [00:00\u003c00:00, 32.64img/s, loss (batch)=5.55]\n","Epoch 3/100: 100% 15/15 [00:00\u003c00:00, 34.42img/s, loss (batch)=5.55]\n","INFO: Validation loss score: 5.548685073852539\n","Epoch 4/100: 100% 15/15 [00:00\u003c00:00, 27.28img/s, loss (batch)=5.54]\n","Epoch 5/100: 100% 15/15 [00:00\u003c00:00, 18.57img/s, loss (batch)=5.54]\n","Epoch 6/100: 100% 15/15 [00:00\u003c00:00, 19.04img/s, loss (batch)=5.53]\n","INFO: Validation loss score: 5.545119285583496\n","Epoch 7/100: 100% 15/15 [00:00\u003c00:00, 16.89img/s, loss (batch)=5.51]\n","Epoch 8/100: 100% 15/15 [00:00\u003c00:00, 17.49img/s, loss (batch)=5.48]\n","Epoch 9/100: 100% 15/15 [00:00\u003c00:00, 28.32img/s, loss (batch)=5.43]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in \u003cmodule\u003e\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 250, in train_model\n","    histograms['Gradients/' + tag] = wandb.Histogram(\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/data_types/histogram.py\", line 76, in __init__\n","    self.histogram, self.bins = np.histogram(sequence, bins=num_bins)\n","  File \"\u003c__array_function__ internals\u003e\", line 180, in histogram\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 793, in histogram\n","    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 426, in _get_bin_edges\n","    first_edge, last_edge = _get_outer_edges(a, range)\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py\", line 323, in _get_outer_edges\n","    raise ValueError(\n","ValueError: autodetected range of [nan, nan] is not finite\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████\n","\u001b[34m\u001b[1mwandb\u001b[0m:   learning rate ▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            step ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train loss █████████████████████▇▇▇▇▆▆▆▆▅▄▄▃▃▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: validation loss █▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 9\n","\u001b[34m\u001b[1mwandb\u001b[0m:   learning rate 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m:            step 36\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train loss 5.43493\n","\u001b[34m\u001b[1mwandb\u001b[0m: validation loss 5.54512\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlight-mountain-60\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/7qvdu23y\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 6 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094916-7qvdu23y/logs\u001b[0m\n"]}],"source":["!python train.py --loss nll -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ca4IvYKTOlw3"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Using device cuda\n","INFO: Model loaded from pre-trained MRI model\n","INFO: Creating dataset with 20 examples\n","INFO: Scanning mask files to determine unique values\n","100% 20/20 [00:00\u003c00:00, 115.12it/s]\n","INFO: Unique mask values: [0, 255]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiangwx7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/wandb/run-20230524_094947-hoyraxyd\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-pond-61\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/hoyraxyd\u001b[0m\n","INFO: Starting training:\n","        Epochs:          100\n","        Loss:            dice\n","        Batch size:      4\n","        Learning rate:   0.0001\n","        Training size:   15\n","        Validation size: 5\n","        Checkpoints:     False\n","        Device:          cuda\n","        Mixed Precision: True\n","    \n","Epoch 1/100:   0% 0/15 [00:01\u003c?, ?img/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 375, in \u003cmodule\u003e\n","    train_model(model=model,\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/train.py\", line 221, in train_model\n","    masks_pred = model(images)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/Othercomputers/xiaoxin/Two-Stage-MedImg-Seg/unet.py\", line 46, in forward\n","    enc1 = self.encoder1(x)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","KeyboardInterrupt\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrural-pond-61\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jiangwx7/DRIVE/runs/hoyraxyd\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230524_094947-hoyraxyd/logs\u001b[0m\n","^C\n"]}],"source":["!python train.py --loss dice -e 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lExA-sH_OnRu"},"outputs":[],"source":["!python train.py --loss dice_bce -e 100"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}